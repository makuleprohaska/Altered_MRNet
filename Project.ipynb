{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90776b0f",
   "metadata": {},
   "source": [
    "<h1>Alexnet Majority Vote</h1>\n",
    "We start by recreating the model used in the orgininal MRNet paper to get a baseline for performance\n",
    "This model uses three Alexnet backbones with a dense classification layer trained on axial, coronal and sagittal MRIs respectively and then uses a majority vote system to determine the final output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b76e02",
   "metadata": {},
   "source": [
    "<h3>Model class</h3>\n",
    "We start by definining the model class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43cadb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "class MRNet3(nn.Module):\n",
    "    \n",
    "    def __init__(self,use_batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.model1 = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        self.model2 = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        self.model3 = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        self.gap = nn.AdaptiveMaxPool2d(1)\n",
    "        # self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        n = 0.15\n",
    "        # Dropout for each view's features\n",
    "        self.dropout_view1 = nn.Dropout(p=n)\n",
    "        self.dropout_view2 = nn.Dropout(p=n)\n",
    "        self.dropout_view3 = nn.Dropout(p=n)\n",
    "        \n",
    "        print(f\"Dropout of {n}\")\n",
    "\n",
    "\n",
    "        classifier_layers_axial = [nn.Linear(256, 256)]\n",
    "        if self.use_batchnorm:\n",
    "            classifier_layers_axial.append(nn.BatchNorm1d(256))\n",
    "        self.classifier1_axial = nn.Sequential(*classifier_layers_axial)\n",
    "\n",
    "        classifier_layers_coronal = [nn.Linear(256, 256)]\n",
    "        if self.use_batchnorm:\n",
    "            classifier_layers_coronal.append(nn.BatchNorm1d(256))\n",
    "        self.classifier1_coronal = nn.Sequential(*classifier_layers_coronal)\n",
    "\n",
    "        classifier_layers_sagittal = [nn.Linear(256, 256)]\n",
    "        if self.use_batchnorm:\n",
    "            classifier_layers_sagittal.append(nn.BatchNorm1d(256))\n",
    "        self.classifier1_sagittal = nn.Sequential(*classifier_layers_sagittal)\n",
    "\n",
    "\n",
    "        # Separate classifier2 for each view\n",
    "        self.classifier2_axial = nn.Linear(256, 1)\n",
    "        self.classifier2_coronal = nn.Linear(256, 1)\n",
    "        self.classifier2_sagittal = nn.Linear(256, 1)\n",
    "\n",
    "\n",
    "    #New forward pass to deal with batch normalisation\n",
    "\n",
    "    def forward(self, x): \n",
    "\n",
    "        # Separate by view\n",
    "        axial_views    = [sample[0] for sample in x]\n",
    "        coronal_views  = [sample[1] for sample in x]\n",
    "        sagittal_views = [sample[2] for sample in x]\n",
    "\n",
    "        def process_view(view_list, model, dropout, classifier1, classifier2):\n",
    "            features = []\n",
    "            for view in view_list:\n",
    "                slices, c, h, w = view.size()  # [num_slices, 3, 224, 224]\n",
    "                view = view.view(slices, c, h, w).to(next(model.parameters()).device)\n",
    "                feat = model.features(view)                     # [slices, 256, 6, 6]\n",
    "                feat = self.gap(feat).view(slices, 256)         # [slices, 256]\n",
    "                feat = torch.max(feat, dim=0)[0]                # [256]\n",
    "                feat = dropout(feat)\n",
    "                features.append(feat)\n",
    "            features = torch.stack(features)                    # [batch_size, 256]\n",
    "            features = classifier1(features)                    # [batch_size, 256]\n",
    "            logits = classifier2(features)                      # [batch_size, 1]\n",
    "            return logits\n",
    "\n",
    "        logit_axial    = process_view(axial_views,    self.model1, self.dropout_view1, self.classifier1_axial, self.classifier2_axial)\n",
    "        logit_coronal  = process_view(coronal_views,  self.model2, self.dropout_view2, self.classifier1_coronal, self.classifier2_coronal)\n",
    "        logit_sagittal = process_view(sagittal_views, self.model3, self.dropout_view3, self.classifier1_sagittal, self.classifier2_sagittal)\n",
    "\n",
    "        logits = torch.stack([logit_axial, logit_coronal, logit_sagittal], dim=0)  # [3, batch_size, 1]\n",
    "        probs = torch.sigmoid(logits)                                              # [3, batch_size, 1]\n",
    "        majority_prob = torch.mean(probs, dim=0)                                   # [batch_size, 1]\n",
    "    \n",
    "        return majority_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8283718",
   "metadata": {},
   "source": [
    "<h3>Loader</h3>\n",
    "Then we have the code to correctly load and preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kornia.augmentation as K\n",
    "import random\n",
    "\n",
    "INPUT_DIM = 224\n",
    "MAX_PIXEL_VAL = 255\n",
    "MEAN = 58.09\n",
    "STDDEV = 49.73\n",
    "\n",
    "class Dataset3(data.Dataset):\n",
    "    def __init__(self, data_dir, file_list, labels_dict, device, train=False, augment=False):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.data_dir_axial = f\"{data_dir}/axial\"\n",
    "        self.data_dir_coronal = f\"{data_dir}/coronal\"\n",
    "        self.data_dir_sagittal = f\"{data_dir}/sagittal\"\n",
    "\n",
    "        self.paths_axial = [os.path.join(self.data_dir_axial, file) for file in file_list]\n",
    "        self.paths_coronal = [os.path.join(self.data_dir_coronal, file) for file in file_list]\n",
    "        self.paths_sagittal = [os.path.join(self.data_dir_sagittal, file) for file in file_list]\n",
    "        \n",
    "        self.paths = [self.paths_axial, self.paths_coronal, self.paths_sagittal]\n",
    "        \n",
    "        self.labels = [labels_dict[file] for file in file_list]\n",
    "\n",
    "        neg_weight = np.mean(self.labels)\n",
    "        self.weights = [neg_weight, 1 - neg_weight]\n",
    "\n",
    "        self.train = train  #this ensures even when augment = True we never perform data augmentation on the validation/test set\n",
    "        self.augment = augment              \n",
    "\n",
    "    def weighted_loss(self, prediction, target, eps: float = 0.0):\n",
    "        # Ensure target is [batch_size, 1]\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        # Compute weights for each sample\n",
    "        weights_npy = np.array([self.weights[int(t.item())] for t in target.flatten()])\n",
    "\n",
    "        # Reshape weights to [batch_size, 1] to match prediction and target\n",
    "        weights_tensor = torch.FloatTensor(weights_npy).view(-1, 1).to(target.device)\n",
    "\n",
    "        smoothed = target * (1 - eps) + (1 - target) * eps # new\n",
    "\n",
    "        # 3) compute BCE with logits against the *smoothed* targets\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, smoothed, weight=weights_tensor) #new\n",
    "        return loss\n",
    "        # # Compute loss with weights reshaped to [batch_size, 1]\n",
    "        # loss = F.binary_cross_entropy_with_logits(prediction, target, weight=weights_tensor)\n",
    "\n",
    "        # return loss\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vol_list = []\n",
    "        for i in range(3):           \n",
    "            path = self.paths[i][index]\n",
    "            vol = np.load(path).astype(np.int32)\n",
    "            pad = int((vol.shape[2] - INPUT_DIM) / 2)\n",
    "            vol = vol[:, pad:-pad, pad:-pad]\n",
    "            vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol)) * MAX_PIXEL_VAL\n",
    "            vol = (vol - MEAN) / STDDEV\n",
    "            vol = np.stack((vol,) * 3, axis=1)\n",
    "            vol_tensor = torch.FloatTensor(vol)  # Keep on CPU\n",
    "            vol_list.append(vol_tensor)\n",
    "\n",
    "            # Apply augmentations if train and augment flags are True\n",
    "            if self.train and self.augment:\n",
    "                vol_tensor = self.apply_augmentations(vol_tensor)\n",
    "        \n",
    "            vol_list.append(vol_tensor)\n",
    "\n",
    "        label_tensor = torch.FloatTensor([self.labels[index]])  # Shape: [1]\n",
    "        return vol_list, label_tensor\n",
    "    \n",
    "    def apply_augmentations(self, vol_tensor):\n",
    "        # Apply same augmentations slice-wise\n",
    "        vol_tensor = K.RandomRotation(degrees=25)(vol_tensor)\n",
    "        vol_tensor = K.RandomAffine(degrees=0, translate=(25/224, 25/224))(vol_tensor)\n",
    "        if random.random() > 0.5:\n",
    "            vol_tensor = K.RandomHorizontalFlip(p=1.0)(vol_tensor)\n",
    "        return vol_tensor\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable slice counts.\n",
    "    Returns a list of view tensors and a stacked label tensor.\n",
    "    \"\"\"\n",
    "    vol_lists = [item[0] for item in batch]  # List of [axial, coronal, sagittal] for each sample\n",
    "    labels = torch.stack([item[1] for item in batch], dim=0)  # Stack labels: [batch_size, 1]\n",
    "    return vol_lists, labels\n",
    "\n",
    "def load_data3(device, data_dir, labels_csv, batch_size=1, augment=False):\n",
    "    labels_df = pd.read_csv(labels_csv, header=None, names=['filename', 'label'])\n",
    "    labels_df['filename'] = labels_df['filename'].apply(lambda x: f\"{int(x):04d}.npy\")\n",
    "    \n",
    "    # Filter files that exist in all 3 views\n",
    "    valid_files = []\n",
    "    valid_labels = []\n",
    "    for _, row in labels_df.iterrows():\n",
    "        fname = row['filename']\n",
    "        exists_all_views = all(os.path.exists(os.path.join(data_dir, view, fname)) for view in ['axial', 'coronal', 'sagittal'])\n",
    "        if exists_all_views:\n",
    "            valid_files.append(fname)\n",
    "            valid_labels.append(row['label'])\n",
    "    \n",
    "    labels_dict = dict(zip(valid_files, valid_labels))\n",
    "\n",
    "    # Stratify split\n",
    "    train_files, valid_files = train_test_split(\n",
    "        valid_files,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=valid_labels\n",
    "    )\n",
    "\n",
    "    train_dataset = Dataset3(data_dir, train_files, labels_dict, device, train=True, augment=augment)\n",
    "    valid_dataset = Dataset3(data_dir, valid_files, labels_dict, device, train=False, augment=False)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=0, \n",
    "        shuffle=True, \n",
    "        pin_memory=device.type == 'cuda',\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    valid_loader = data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=0, \n",
    "        shuffle=False, \n",
    "        pin_memory=device.type == 'cuda',\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def load_data_test(device, data_dir, labels_csv, batch_size=1, label_smoothing=0):\n",
    "    labels_df = pd.read_csv(labels_csv, header=None, names=['filename', 'label'])\n",
    "    labels_df['filename'] = labels_df['filename'].apply(lambda x: f\"{int(x):04d}.npy\")\n",
    "    labels_dict = dict(zip(labels_df['filename'], labels_df['label']))\n",
    "\n",
    "    test_files = [f for f in os.listdir(f\"{data_dir}/axial\") if f.endswith(\".npy\")]\n",
    "    test_files = [f for f in test_files if f in labels_dict]\n",
    "    test_files.sort()\n",
    "\n",
    "    test_dataset = MRDataset(data_dir, test_files, labels_dict, device, train=False, label_smoothing=label_smoothing, augment=False)\n",
    "\n",
    "    test_loader = data.DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=0, \n",
    "        shuffle=False, \n",
    "        pin_memory=device.type == 'cuda',\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868555f",
   "metadata": {},
   "source": [
    "<h3>Training and evaluation functions</h3>\n",
    "Lastly we define the functions to run training and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b06695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_device(use_gpu, use_mps):\n",
    "    \n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    \n",
    "    elif use_mps and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    \n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def run_model(model, loader, train=False, optimizer=None, eps: float = 0.0):\n",
    "    \"\"\"\n",
    "    model    : your MRNet3 instance\n",
    "    loader   : DataLoader returning (vol_lists, label)\n",
    "    train    : whether to do optimizer.step()\n",
    "    optimizer: your Adam optimizer (only used if train=True)\n",
    "    eps      : label-smoothing factor (0.0 = no smoothing)\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    device = loader.dataset.device\n",
    "\n",
    "    for vol_lists, label in tqdm(loader, desc=\"Processing batches\", total=len(loader)):\n",
    "        # Move data to device\n",
    "        label = label.to(device)                       # [batch_size,1]\n",
    "        vol_lists = [[view.to(device) for view in views] for views in vol_lists]\n",
    "\n",
    "        # Forward\n",
    "        logits = model(vol_lists)                      # [batch_size,1]\n",
    "        probs  = torch.sigmoid(logits)                 # [batch_size,1]\n",
    "\n",
    "        # Loss\n",
    "        if train:\n",
    "            # use smoothing in training\n",
    "            loss = loader.dataset.weighted_loss(logits, label, eps=eps)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            # no smoothing in val/test\n",
    "            loss = loader.dataset.weighted_loss(logits, label, eps=0.0)\n",
    "\n",
    "        # Accumulate\n",
    "        total_loss += loss.item()\n",
    "        preds.extend(probs.detach().cpu().view(-1).tolist())\n",
    "        labels.extend(label.detach().cpu().view(-1).tolist())\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, preds)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    return avg_loss, auc, preds, labels\n",
    "\n",
    "def evaluate(split, model_path, use_gpu, mps, data_dir, labels_csv):\n",
    "    device = get_device(use_gpu, mps)\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    \n",
    "    if split == 'test' or split == 'valid':\n",
    "        train_loader, valid_loader = load_data3(device, data_dir, labels_csv)\n",
    "    elif split == 'train':\n",
    "        train_loader = load_data_train(device, data_dir, labels_csv, augment=True)\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n",
    "    \n",
    "    model = MRNet3()\n",
    "    \n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if split == 'train':\n",
    "        loader = train_loader\n",
    "    elif split == 'valid':\n",
    "        loader = valid_loader\n",
    "    elif split == 'test':\n",
    "        loader = test_loader\n",
    "\n",
    "    loss, auc, preds, labels = run_model(model, loader, train=False)\n",
    "    print(f'{split} loss: {loss:.4f}')\n",
    "    print(f'{split} AUC: {auc:.4f}')\n",
    "    return preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47e7abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "\n",
    "def get_device(use_gpu, use_mps):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif use_mps and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def train3(rundir, epochs, learning_rate, use_gpu, use_mps, data_dir, labels_csv, weight_decay, max_patience, batch_size, augment, epsilon):\n",
    "    device = get_device(use_gpu, use_mps)\n",
    "    print(f\"Using device: {device}\")\n",
    "    train_loader, valid_loader = load_data3(device, data_dir, labels_csv, batch_size=batch_size, augment=augment)\n",
    "    \n",
    "\n",
    "    #This now deals with the case that batch size is 1\n",
    "    use_batchnorm = batch_size > 1\n",
    "    model = MRNet3(use_batchnorm=use_batchnorm)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"Using BatchNorm: {use_batchnorm}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=max_patience, factor=.3, threshold=1e-4)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    print(f\"Value of eps:{epsilon}\")\n",
    "    for epoch in range(epochs):\n",
    "        change = datetime.now() - start_time\n",
    "        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n",
    "        \n",
    "        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer, eps=epsilon)\n",
    "        print(f'train loss: {train_loss:0.4f}')\n",
    "        print(f'train AUC: {train_auc:0.4f}')\n",
    "\n",
    "        val_loss, val_auc, _, _ = run_model(model, valid_loader, eps=0.0)\n",
    "        print(f'valid loss: {val_loss:0.4f}')\n",
    "        print(f'valid AUC: {val_auc:0.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            file_name = f'val{val_loss:0.4f}_train{train_loss:0.4f}_epoch{epoch+1}'\n",
    "            save_path = Path(rundir) / file_name \n",
    "            # -torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        # Log metrics to file\n",
    "        with open(os.path.join(rundir, 'metrics.txt'), 'a') as f:\n",
    "            f.write(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, train_auc={train_auc:.4f}, val_auc={val_auc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a4b91",
   "metadata": {},
   "source": [
    "<h3>Training</h3>\n",
    "Now we train the model we found the best parameters to be (parameters). As in the original paper, each sample was randomly rotated by an angle between -25 adn 25 degrees, randomly translated by up to 25 pixels and flipped horizontaly with probability 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41d705d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training samples: 904, Validation samples: 226\n",
      "Dropout of 0.15\n",
      "Using BatchNorm: False\n",
      "Value of eps:0.0\n",
      "starting epoch 1. time passed: 0:00:00.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 30/904 [00:07<03:26,  4.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(Path(rundir) / \u001b[33m'\u001b[39m\u001b[33margs.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m     43\u001b[39m     json.dump(params, out, indent=\u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mtrain3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrundir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mtrain3\u001b[39m\u001b[34m(rundir, epochs, learning_rate, use_gpu, use_mps, data_dir, labels_csv, weight_decay, max_patience, batch_size, augment, epsilon)\u001b[39m\n\u001b[32m     40\u001b[39m change = datetime.now() - start_time\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mstarting epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. time passed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(epoch+\u001b[32m1\u001b[39m, \u001b[38;5;28mstr\u001b[39m(change)))\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m train_loss, train_auc, _, _ = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model, loader, train, optimizer, eps)\u001b[39m\n\u001b[32m     37\u001b[39m     model.eval()\n\u001b[32m     39\u001b[39m device = loader.dataset.device\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvol_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing batches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move data to device\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# [batch_size,1]\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvol_lists\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mview\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mviews\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mviews\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvol_lists\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mDataset3.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Apply augmentations if train and augment flags are True\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.augment:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m         vol_tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_augmentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvol_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     vol_list.append(vol_tensor)\n\u001b[32m     77\u001b[39m label_tensor = torch.FloatTensor([\u001b[38;5;28mself\u001b[39m.labels[index]])  \u001b[38;5;66;03m# Shape: [1]\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mDataset3.apply_augmentations\u001b[39m\u001b[34m(self, vol_tensor)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_augmentations\u001b[39m(\u001b[38;5;28mself\u001b[39m, vol_tensor):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# Apply same augmentations slice-wise\u001b[39;00m\n\u001b[32m     82\u001b[39m     vol_tensor = K.RandomRotation(degrees=\u001b[32m25\u001b[39m)(vol_tensor)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     vol_tensor = \u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRandomAffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdegrees\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m/\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m/\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvol_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m random.random() > \u001b[32m0.5\u001b[39m:\n\u001b[32m     85\u001b[39m         vol_tensor = K.RandomHorizontalFlip(p=\u001b[32m1.0\u001b[39m)(vol_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/core/module.py:302\u001b[39m, in \u001b[36mImageModule.__call__\u001b[39m\u001b[34m(self, input_names_to_handle, output_type, *inputs, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._disable_features:\n\u001b[32m    299\u001b[39m     decorated_forward = \u001b[38;5;28mself\u001b[39m.convert_input_output(\n\u001b[32m    300\u001b[39m         input_names_to_handle=input_names_to_handle, output_type=output_type\n\u001b[32m    301\u001b[39m     )(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     _output_image = \u001b[43mdecorated_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_type == \u001b[33m\"\u001b[39m\u001b[33mtensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    304\u001b[39m         \u001b[38;5;28mself\u001b[39m._output_image = \u001b[38;5;28mself\u001b[39m._detach_tensor_to_cpu(_output_image)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/core/module.py:81\u001b[39m, in \u001b[36mImageModuleMixIn.convert_input_output.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m             kwargs[name] = \u001b[38;5;28mself\u001b[39m.to_tensor(value)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Call the actual forward method\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m tensor_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor_outputs, (\u001b[38;5;28mtuple\u001b[39m,)):\n\u001b[32m     84\u001b[39m     tensor_outputs = (tensor_outputs,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/augmentation/base.py:258\u001b[39m, in \u001b[36m_BasicAugmentationBase.forward\u001b[39m\u001b[34m(self, input, params, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mbatch_prob\u001b[39m\u001b[33m\"\u001b[39m] = tensor([\u001b[38;5;28;01mTrue\u001b[39;00m] * batch_shape[\u001b[32m0\u001b[39m])\n\u001b[32m    256\u001b[39m params, flags = \u001b[38;5;28mself\u001b[39m._process_kwargs_to_params_and_flags(params, \u001b[38;5;28mself\u001b[39m.flags, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform_output_tensor(output, input_shape) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keepdim \u001b[38;5;28;01melse\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/augmentation/_2d/base.py:148\u001b[39m, in \u001b[36mRigidAffineAugmentationBase2D.apply_func\u001b[39m\u001b[34m(self, in_tensor, params, flags)\u001b[39m\n\u001b[32m    145\u001b[39m     flags = \u001b[38;5;28mself\u001b[39m.flags\n\u001b[32m    147\u001b[39m trans_matrix = \u001b[38;5;28mself\u001b[39m.generate_transformation_matrix(in_tensor, params, flags)\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m._transform_matrix = trans_matrix\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/augmentation/base.py:323\u001b[39m, in \u001b[36m_AugmentationBase.transform_inputs\u001b[39m\u001b[34m(self, input, params, flags, transform, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# If any tensor needs to be transformed.\u001b[39;00m\n\u001b[32m    322\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.apply_non_transform(in_tensor, params, flags, transform=transform)\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     applied = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mto_apply\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m[\u001b[49m\u001b[43mto_apply\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_autocast_enabled():\n\u001b[32m    331\u001b[39m         output = output.type(\u001b[38;5;28minput\u001b[39m.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/augmentation/_2d/geometric/affine.py:133\u001b[39m, in \u001b[36mRandomAffine.apply_transform\u001b[39m\u001b[34m(self, input, params, flags, transform)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, Tensor):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected the `transform` be a Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(transform)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwarp_affine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresample\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43malign_corners\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpadding_mode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/kornia/geometry/transform/imgwarp.py:219\u001b[39m, in \u001b[36mwarp_affine\u001b[39m\u001b[34m(src, M, dsize, mode, padding_mode, align_corners, fill_value)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# src_norm_trans_dst_norm = torch.inverse(dst_norm_trans_src_norm)\u001b[39;00m\n\u001b[32m    217\u001b[39m src_norm_trans_dst_norm = _torch_inverse_cast(dst_norm_trans_src_norm)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m grid = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_norm_trans_dst_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding_mode == \u001b[33m\"\u001b[39m\u001b[33mfill\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/torch/nn/functional.py:5125\u001b[39m, in \u001b[36maffine_grid\u001b[39m\u001b[34m(theta, size, align_corners)\u001b[39m\n\u001b[32m   5122\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(size) <= \u001b[32m0\u001b[39m:\n\u001b[32m   5123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected non-zero, positive output size. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine_grid_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rundir =  \"/Users/matteobruno/Desktop/runs\"  #\"directory/to/store/runs\"\n",
    "data_dir = \"/Users/matteobruno/Desktop/MRNet-v1.0/train\" #\"Directory/containing/.npy_files'\"\n",
    "labels_csv =  \"/Users/matteobruno/Desktop/MRNet-v1.0/train/train-acl.csv\" #\"Path/to/labels/CSV/file\"\n",
    "seed = 42\n",
    "gpu = False #If true runs on Nvidia GPU\n",
    "mps = True #If true runs on Apple MPS\n",
    "learning_rate = 1e-05\n",
    "weight_decay = 0.01\n",
    "epochs = 50\n",
    "max_patience = 5\n",
    "factor = 0.3 \n",
    "batch_size = 1 \n",
    "eps = 0.0 #Label smoothing factor (0.0 = no smoothing)'\n",
    "augment = True  #Apply data augmentation during training\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "elif mps and torch.backends.mps.is_available():\n",
    "    pass\n",
    "\n",
    "os.makedirs(rundir, exist_ok=True)\n",
    "\n",
    "# Save parameters to args.json\n",
    "params = {\n",
    "    \"rundir\": rundir,\n",
    "    \"data_dir\": data_dir,\n",
    "    \"labels_csv\": labels_csv,\n",
    "    \"seed\": seed,\n",
    "    \"gpu\": gpu,\n",
    "    \"mps\": mps,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"epochs\": epochs,\n",
    "    \"max_patience\": max_patience,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"label_smoothing\": eps,\n",
    "    \"augment\": augment\n",
    "}\n",
    "with open(Path(rundir) / 'args.json', 'w') as out:\n",
    "    json.dump(params, out, indent=4)\n",
    "\n",
    "    train3(rundir, epochs, learning_rate, \n",
    "        gpu, mps, data_dir, labels_csv, weight_decay, max_patience, batch_size, augment, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model_path MODEL_PATH --split SPLIT\n",
      "                             --diagnosis DIAGNOSIS --data_dir DATA_DIR\n",
      "                             --labels_csv LABELS_CSV [--gpu] [--mps]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model_path, --split, --diagnosis, --data_dir, --labels_csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mrnet/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3557: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "model_path = \"path/to/your/model.pth\"  # Path to the saved model\n",
    "split = \"test\"  # or \"train\", \"valid\"\n",
    "data_dir = \"/Users/matteobruno/Desktop/MRNet-v1.0/test\" #\"Directory/containing/.npy_files'\"\n",
    "labels_csv =  \"/Users/matteobruno/Desktop/MRNet-v1.0/train/train-acl.csv\" #\"Path/to/labels/CSV/file\"\n",
    "gpu = False #If true runs on Nvidia GPU\n",
    "mps = True #If true runs on Apple MPS\n",
    "\n",
    "\n",
    "# Save parameters to args.json\n",
    "params = {\n",
    "    \"model_path\": model_path,\n",
    "    \"split\": split,\n",
    "    \"data_dir\": data_dir,\n",
    "    \"labels_csv\": labels_csv,\n",
    "    \"gpu\": gpu,\n",
    "    \"mps\": mps\n",
    "}\n",
    "\n",
    "evaluate(split, model_path, gpu, mps, data_dir, labels_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
